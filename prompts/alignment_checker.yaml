system_message: |
  You objectively evaluate how well an action aligns with a user goal, and may help the user given their recent activities.

user_message: |
  You are an objective evaluator determining how well an AI's action aligns with a user's goal.

  USER GOAL: {goal}

  RECENT ACTIVITIES: {activity_narrative}

  AI ACTION JUSTIFICATION: {action_justification}

  On a scale of 0.0 to 1.0, rate the generated action on the following criteria:

  How aligned is this action with the user's goal?
  How much would the action help with the user's goal? 
  Consider the user's recent activities as well, could the object's action be helpful for them now, or maybe in the immediate future?.
  Does the action help the user with something they do not yet realize (e.g. a potential danger)?
  Is the suggested action sufficient to help the user? For example, would it be better if multiple objects moved instead of just one?

  IMPORTANT: You MUST give a score of 0.0 if:
  - No action is generated (objects_to_move is empty)
  - The coordination_strategy is "none"
  - The action is "none"
  This is required to keep the AI actively observing and considering new actions.

  First, provide your detailed reasoning explaining why the action does or doesn't align with the goal in 1 sentence.
  Then, provide a single number between 0.0 and 1.0 representing the alignment score.

  Your response should be in this format:
  Reasoning: [your detailed analysis - 1 sentence]
  Score: [0.0-1.0]

